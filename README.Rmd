---
title: "KDD Cup 99 - H2O and R"
author: "Jose A. Dianes"
date: "6 April 2015"
output:
  html_document:
    keep_md: yes
    theme: cerulean
    toc: yes
---

My try with [KDD Cup 99](http://kdd.ics.uci.edu/databases/kddcup99/task.html) 
using [H2O](http://0xdata.com/) and `R`. The dataset for this data mining 
competition can be found 
[here](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html).  

## Task description summary  

You can find the complete description of the task 
[here](http://kdd.ics.uci.edu/databases/kddcup99/task.html).  

Software to detect network intrusions protects a computer network from
unauthorized users, including perhaps insiders.  The intrusion detector learning
task is to build a predictive model (i.e. a classifier) capable of
distinguishing between *bad connections*, called intrusions or attacks, and
*good normal connections*.  

A connection is a sequence of TCP packets starting and ending at some well
defined times, between which data flows to and from a source IP address to a
target IP address under some well defined protocol.  Each connection is labeled
as either normal, or as an attack, with exactly one specific attack type.  Each
connection record consists of about 100 bytes.  

Attacks fall into four main categories:  

- DOS: denial-of-service, e.g. syn flood;  
- R2L: unauthorized access from a remote machine, e.g. guessing password;  
- U2R:  unauthorized access to local superuser (root) privileges, e.g., various
``buffer overflow'' attacks;  
- probing: surveillance and other probing, e.g., port scanning.  

It is important to note that the test data is not from the same probability
distribution as the training data, and it includes specific attack types not in
the training data. This makes the task more realistic. The datasets contain a
total of 24 training attack types, with an additional 14 types in the test data
only.   

Some intrusion experts believe that most novel attacks are variants of known
attacks and the "signature" of known attacks can be sufficient to catch novel
variants. Based on this idea, we will experiment with different machine learning
approaches.   

## Approach

We will start by loading the data and do some exploratory data analysis using.
Then we will build a classifier using `H2O` *random forest* implementation.  

However, in our final approach we want to use clustering and anomality
detection. We want our model to be able to work well with unknown attack types
and also to give an approchimation of the closest attack type.   

## Libraries and global settings used  

```{r, message=FALSE, warning=FALSE}
library(ggplot2)
theme_set(theme_linedraw())
library(pander)
library(h2o)
```

## Connecting to H2O cluster  

First we need to set the connection settings.  

```{r, message=FALSE, warning = FALSE}
h2o_ip <- '169.254.206.2'
h2o_port <- 54321
```

Now we can connect to our cluster.  

```{r}
jupiterH2O <- h2o.init(ip = h2o_ip, port=h2o_port)
```

## Reading data 

Now we are ready to read our data files. We have it stored in the 
cluster's NFS structure. In H2O, we assign logical names to those data files 
that we read into memory (e.g. `key_data_name`). In our case:  

- **`kdd_data.hex`**: contains the training data.  
- **`kdd_corrected.hex`**: contains the labeled data that will be used 
for testing purposes.  

```{r}
key_name_data <- "kdd_data.hex"
system.time(
    kdd_data.hex <- h2o.importFile(
        jupiterH2O, 
        path = "/nfs/data/KDD99/kddcup.data", 
        key = key_name_data)
)
train_size <- nrow(kdd_data.hex)
```

We also need to read the test data by following the same process.  

```{r}
key_name_corrected <- "kdd_corrected.hex"
system.time(
    kdd_corrected.hex <- h2o.importFile(
        jupiterH2O, 
        path = "/nfs/data/KDD99/corrected", 
        key = key_name_corrected)
)
test_size <- nrow(kdd_corrected.hex)
```

Notice how, once we have the data in memory, they are represented as data frames 
and we can check their sizes using for example `nrow`. For the train data we 
have `r train_size` entries. For test data we have `r test_size`.  

Finally we can sumarise as we do with regular data frames.  

```{r}
summary(kdd_data.hex)
```

## Data exploration  

The good thing about using `H2O` from R is that we have access to the usual way
of exploring data with R. We just need to use the way of applying functions 
proposed by `H2O`.  

For example, let's install a function to take the mean of the duration column.  

```{r}
duration_mean <- function(df) { mean(df[,1]) }
h2o.addFunction(jupiterH2O, duration_mean)
```

Now we can apply the function to different label groups by using `ddply`, that
works with `H2O` `hex` objects.    

```{r}
res <- h2o.ddply(kdd_data.hex, "C42", duration_mean)
by_label_means <- as.data.frame(head(res,23))

# h2o seems to be inconsistent when labeling factor results
label_names <- levels(kdd_data.hex[,42])
if (!is.factor(by_label_means$C42)) {
    by_label_means$C42 <- as.factor(label_names[by_label_means$C42+1])
}
```

Now we can plot using `ggplot`. Let's see the mean duration by label.    

```{r, fig.width=10, fig.height=4}
ggplot(data=by_label_means, aes(x=C42, y=C1)) +
    geom_bar(stat="identity", color="grey", fill="lightblue") +
    xlab("Label") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
    ylab("Duration")
```

## Training a classifier  

The `H2O` framework offers a rich machine learning library. In this case we will
train a *random forest* classifier. We will try with every single predictor.  

```{r, cache=TRUE}
system.time(
    kdd_data.rf <- h2o.randomForest(y = 42, x = c(1:41), data = kdd_data.hex, 
                                ntree = 100, depth = 500)
)
```

We have just trained a *random forest* for more than 4 million entries of data 
and 41 predictors.  

We can print the resulting tree object, that contains among other things a
confusion matrix.  

```{r}
print(kdd_data.rf)
```


###  Predicting labels using testing data  

```{r}
kdd_data.rf.pred <- h2o.predict(kdd_data.rf, newdata=kdd_corrected.hex)
head(kdd_data.rf.pred)
```

Get accuracy (h2o result gives problems with colums 20 and 22, don't know why...).  

```{r}
accuracies <- sapply(
    c(1:19,21,23), 
    function(x) {  h2o.performance(kdd_data.rf.pred[,x+1], kdd_corrected.hex$C42==label_names[x])@model$accuracy }
    )
accuracy <- mean(accuracies)
```

Plot accuracies.  

```{r, fig.width=10, fig.height=4}
accuracies.df <- data.frame(label=label_names[c(1:19,21,23)], accuracy=accuracies)
ggplot(data=accuracies.df, aes(x=label, y=accuracy)) +
    geom_bar(stat="identity", color="grey", fill="lightblue") +
    xlab("Label") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
    ylab("Prediction accuracy")
```


## Clustering data  

Clustering by using *k-means* is as easy as use the corresponsing part of the 
`H2O` library for `R`.  

We will cluster for `k = 40` (at least we have 23 different labels in our 
dataset). Of course we don't use the label to cluster the data. Moreover k-means
just works with numeric data, we can't use some predictors like they are such as
`protocol`, `service`, or `flag`.  

```{r, cache=TRUE}
system.time(
    kdd_data.km <- h2o.kmeans(
        data = kdd_data.hex, 
        centers = 40, 
        cols = c(1,5:41), 
        normalize=T,
        iter.max=10)
)
```

The clustering process is faster than training a *random forest* but not by a lot.  

Sadly, the current *k-means* implementation doesn't return the cluster to data 
assignments. If we see the documentation it was there before, but we can't find it
in the version we used in this analysis.  

But we can print the contains of the resulting object.  

```{r}
kdd_data.km
```
